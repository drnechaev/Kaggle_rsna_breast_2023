{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ef437d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-25T14:38:07.308503Z",
     "iopub.status.busy": "2023-02-25T14:38:07.307556Z",
     "iopub.status.idle": "2023-02-25T14:39:02.396847Z",
     "shell.execute_reply": "2023-02-25T14:39:02.395598Z"
    },
    "papermill": {
     "duration": 55.099964,
     "end_time": "2023-02-25T14:39:02.399698",
     "exception": false,
     "start_time": "2023-02-25T14:38:07.299734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/dicomsdl-offline-installer/dicomsdl-0.109.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\n",
      "Installing collected packages: dicomsdl\r\n",
      "Successfully installed dicomsdl-0.109.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/keras-cv-attention-models/keras_cv_attention_models-1.3.9-py3-none-any.whl\r\n",
      "Installing collected packages: keras-cv-attention-models\r\n",
      "Successfully installed keras-cv-attention-models-1.3.9\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/dicomsdl-offline-installer/dicomsdl-0.109.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
    "!pip install --no-deps /kaggle/input/keras-cv-attention-models/keras_cv_attention_models-1.3.9-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d43e49ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-25T14:39:02.413800Z",
     "iopub.status.busy": "2023-02-25T14:39:02.412854Z",
     "iopub.status.idle": "2023-02-25T14:39:12.467516Z",
     "shell.execute_reply": "2023-02-25T14:39:12.466541Z"
    },
    "papermill": {
     "duration": 10.064413,
     "end_time": "2023-02-25T14:39:12.470192",
     "exception": false,
     "start_time": "2023-02-25T14:39:02.405779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import dicomsdl\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "from enum import Enum\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ddc1f3",
   "metadata": {
    "papermill": {
     "duration": 0.005619,
     "end_time": "2023-02-25T14:39:12.481567",
     "exception": false,
     "start_time": "2023-02-25T14:39:12.475948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating and preproccesing DataSet\n",
    "1. from traing set get 'site_id','patient_id','image_id', 'laterality','view','age','implant','cancer'\n",
    "2. Since routine examination includes MLO and CC projections, we droped all another projections\n",
    "3. Croping and fliping image ro one side\n",
    "4. Merge MLO and CC layers, cause we need a general picture of the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68447c78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-25T14:39:12.494292Z",
     "iopub.status.busy": "2023-02-25T14:39:12.493789Z",
     "iopub.status.idle": "2023-02-25T14:39:12.498650Z",
     "shell.execute_reply": "2023-02-25T14:39:12.497607Z"
    },
    "papermill": {
     "duration": 0.013792,
     "end_time": "2023-02-25T14:39:12.501014",
     "exception": false,
     "start_time": "2023-02-25T14:39:12.487222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_path = '/kaggle/input/rsna-breast-cancer-detection/train.csv'\n",
    "\n",
    "imgs_path = '/kaggle/input/rsna-breast-cancer-detection/train_images'\n",
    "imgs_path_png = '/kaggle/input/rsna-mammography-images-as-pngs/images_as_pngs_cv2_vl_asp_1024/train_images_processed_cv2_vl_asp_1024'\n",
    "test_csv_path = '/kaggle/input/rsna-breast-cancer-detection/test.csv'\n",
    "test_imgs_path = '/kaggle/input/rsna-breast-cancer-detection/test_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4b35051",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-25T14:39:12.513631Z",
     "iopub.status.busy": "2023-02-25T14:39:12.512826Z",
     "iopub.status.idle": "2023-02-25T14:39:19.242763Z",
     "shell.execute_reply": "2023-02-25T14:39:19.241519Z"
    },
    "papermill": {
     "duration": 6.739286,
     "end_time": "2023-02-25T14:39:19.245874",
     "exception": false,
     "start_time": "2023-02-25T14:39:12.506588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on CPU or GPU\n",
      "N_REPLICAS: 2, IS_TPU: False\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    print('Running on TPU ', TPU.master())\n",
    "except ValueError:\n",
    "    print('Running on CPU or GPU')\n",
    "    TPU = None\n",
    "    \n",
    "if TPU:\n",
    "    IS_TPU = True\n",
    "    tf.config.experimental_connect_to_cluster(TPU)\n",
    "    tf.tpu.experimental.initialize_tpu_system(TPU)\n",
    "    STRATEGY = tf.distribute.experimental.TPUStrategy(TPU)\n",
    "else:\n",
    "    IS_TPU = False\n",
    "    STRATEGY = tf.distribute.MirroredStrategy()\n",
    "\n",
    "\n",
    "N_REPLICAS = STRATEGY.num_replicas_in_sync\n",
    "BATCH_SIZE = 8 * N_REPLICAS\n",
    "N_EPOCHS = 10\n",
    "\n",
    "#IMAGE_SHAPE\n",
    "#img_shape = (256,448)\n",
    "img_shape = (768,1344)\n",
    "\n",
    "\n",
    "TRAIN_SETS=10\n",
    "\n",
    "\n",
    "print(f'N_REPLICAS: {N_REPLICAS}, IS_TPU: {IS_TPU}')\n",
    "\n",
    "policy = tf.keras.mixed_precision.Policy('float32')\n",
    "tf.keras.mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e75c894a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-25T14:39:19.259082Z",
     "iopub.status.busy": "2023-02-25T14:39:19.258772Z",
     "iopub.status.idle": "2023-02-25T14:39:19.263702Z",
     "shell.execute_reply": "2023-02-25T14:39:19.262657Z"
    },
    "papermill": {
     "duration": 0.013739,
     "end_time": "2023-02-25T14:39:19.265706",
     "exception": false,
     "start_time": "2023-02-25T14:39:19.251967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class Side(Enum):\n",
    "    LEFT = 1\n",
    "    RIGHT = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc57c8fa",
   "metadata": {
    "papermill": {
     "duration": 0.005322,
     "end_time": "2023-02-25T14:39:19.276725",
     "exception": false,
     "start_time": "2023-02-25T14:39:19.271403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "PreprocessImage base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2e5a032",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-25T14:39:19.288839Z",
     "iopub.status.busy": "2023-02-25T14:39:19.288571Z",
     "iopub.status.idle": "2023-02-25T14:39:19.296112Z",
     "shell.execute_reply": "2023-02-25T14:39:19.295106Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.01591,
     "end_time": "2023-02-25T14:39:19.298251",
     "exception": false,
     "start_time": "2023-02-25T14:39:19.282341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def crop(img):\n",
    "    # Binarize the image\n",
    "    bin_pixels = cv2.threshold(img, 20, 255, cv2.THRESH_BINARY)[1]\n",
    "   \n",
    "    # Make contours around the binarized image, keep only the largest contour\n",
    "    contours, _ = cv2.findContours(bin_pixels, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Create a mask from the largest contour\n",
    "    mask = np.zeros(img.shape, np.uint8)\n",
    "    cv2.drawContours(mask, [contour], -1, 255, cv2.FILLED)\n",
    "   \n",
    "    # Use bitwise_and to get masked part of the original image\n",
    "    out = cv2.bitwise_and(img, mask)\n",
    "    \n",
    "    # get bounding box of contour\n",
    "    y1, y2 = np.min(contour[:, :, 1]), np.max(contour[:, :, 1])\n",
    "    x1, x2 = np.min(contour[:, :, 0]), np.max(contour[:, :, 0])\n",
    "    \n",
    "    x1 = int(0.99 * x1)\n",
    "    x2 = int(1.01 * x2)\n",
    "    y1 = int(0.99 * y1)\n",
    "    y2 = int(1.01 * y2)\n",
    "\n",
    "\n",
    "    return out[y1:y2, x1:x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a664175",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-25T14:39:19.310436Z",
     "iopub.status.busy": "2023-02-25T14:39:19.310152Z",
     "iopub.status.idle": "2023-02-25T14:39:19.322945Z",
     "shell.execute_reply": "2023-02-25T14:39:19.322028Z"
    },
    "papermill": {
     "duration": 0.021496,
     "end_time": "2023-02-25T14:39:19.325233",
     "exception": false,
     "start_time": "2023-02-25T14:39:19.303737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PreprocessImage:\n",
    "    \n",
    "    def __init__(self, img_path, img_size=(512,512),flip=True, side=Side.LEFT, crop=True):\n",
    "        self.img_path = img_path\n",
    "        self.img_size = img_size\n",
    "        self.flip = flip\n",
    "        self.side = side\n",
    "        self.crop = crop\n",
    "    \n",
    "    def loadXray(self, file_path):\n",
    "        pass\n",
    "    \n",
    "    def getExt(self):\n",
    "        pass\n",
    "    \n",
    "    def getImgPath(self):\n",
    "        return self.img_path\n",
    "    \n",
    "    def readXray(self, file_path):\n",
    "        img = self.loadXray(file_path)\n",
    "        \n",
    "        if self.flip:\n",
    "            if self.determine_side(img) != self.side:\n",
    "                img = cv2.flip(img,1)\n",
    "\n",
    "        if self.crop:\n",
    "            \"\"\"\n",
    "            coords = cv2.findNonZero(img) # Find all non-zero points (text)\n",
    "            x, y, w, h = cv2.boundingRect(coords) # Find minimum spanning bounding box\n",
    "            img = img[y:y+h, x:x+w]\n",
    "            \"\"\"\n",
    "            img = crop(img)\n",
    "\n",
    "        if self.img_size:\n",
    "            img = cv2.resize(img, self.img_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Add channel dim at First\n",
    "        img = img[:,:,np.newaxis]\n",
    "\n",
    "        # Converting img to float32\n",
    "        img = img / np.max(img)\n",
    "        img = img.astype(\"float32\")\n",
    "\n",
    "        return img\n",
    "    \n",
    "    def determine_side(self,img, threshold = 5):\n",
    "\n",
    "        w0 = img.shape[1]\n",
    "        #where score was 0.5\n",
    "        \n",
    "        if img[:,int(-w0 * 0.10):].sum() > img[:,:int(w0 * 0.10)].sum():\n",
    "            return Side.RIGHT\n",
    "        else:\n",
    "            return Side.LEFT\n",
    "        \n",
    "        \"\"\"width = img.shape[1]\n",
    "        if sum(sum(img[:, :1])) > sum(sum(img[:, width-1:])): \n",
    "            return Side.LEFT\n",
    "        else:\n",
    "            return Side.RIGHT\"\"\"\n",
    "    \n",
    "    \n",
    "    def getSplitXray(self, mlo_path,cc_path,age=0):\n",
    "    \n",
    "        mlo = self.readXray(self.img_path+mlo_path)\n",
    "        cc  = self.readXray(self.img_path+cc_path)\n",
    "        zeros = np.full(( self.img_size[1],self.img_size[0],1 ), min(age/100,1.0), dtype='float32')\n",
    "\n",
    "        img = np.concatenate((mlo, cc,zeros), axis=2) \n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc505d",
   "metadata": {
    "papermill": {
     "duration": 0.005244,
     "end_time": "2023-02-25T14:39:19.337169",
     "exception": false,
     "start_time": "2023-02-25T14:39:19.331925",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Loader for DICOMS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2723dcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-25T14:39:19.349731Z",
     "iopub.status.busy": "2023-02-25T14:39:19.349445Z",
     "iopub.status.idle": "2023-02-25T14:39:19.360166Z",
     "shell.execute_reply": "2023-02-25T14:39:19.359332Z"
    },
    "papermill": {
     "duration": 0.019563,
     "end_time": "2023-02-25T14:39:19.362384",
     "exception": false,
     "start_time": "2023-02-25T14:39:19.342821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PreprocessImageDICOM(PreprocessImage):\n",
    "\n",
    "    def loadXray(self, file_path):\n",
    "        dicom = dicomsdl.open(file_path)\n",
    "        data = dicom.pixelData(storedvalue=False)  # storedvalue = True for int16 return otherwise float32\n",
    "        \n",
    "        try:\n",
    "            data = self.voi_lut(data,dicom)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "\n",
    "        if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "            data = np.max(data) - data\n",
    "            \n",
    "        data = (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "        # Convert to uint8 image in range [0, 255]\n",
    "        data = (data * 255).astype(np.uint8)\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def voi_lut(self,img,dataset):\n",
    "         # Load only the variables we need\n",
    "        center = dataset[\"WindowCenter\"]\n",
    "        width = dataset[\"WindowWidth\"]\n",
    "        bits_stored = dataset[\"BitsStored\"]\n",
    "        voi_lut_function = dataset[\"VOILUTFunction\"]\n",
    "\n",
    "        # For sigmoid it's a list, otherwise a single value\n",
    "        if isinstance(center, list):\n",
    "            center = center[0]\n",
    "        if isinstance(width, list):\n",
    "            width = width[0]\n",
    "\n",
    "        # Set y_min, max & range\n",
    "        y_min = 0\n",
    "        y_max = float(2**bits_stored - 1)\n",
    "        y_range = y_max\n",
    "\n",
    "        # Function with default LINEAR (so for Nan, it will use linear)\n",
    "        if voi_lut_function == \"SIGMOID\":\n",
    "            img = y_range / (1 + np.exp(-4 * (img - center) / width)) + y_min\n",
    "        else:\n",
    "            # Checks width for < 1 (in our case not necessary, always >= 750)\n",
    "            center -= 0.5\n",
    "            width -= 1\n",
    "\n",
    "            below = img <= (center - width / 2)\n",
    "            above = img > (center + width / 2)\n",
    "            between = np.logical_and(~below, ~above)\n",
    "\n",
    "            img[below] = y_min\n",
    "            img[above] = y_max\n",
    "            if between.any():\n",
    "                img[between] = (\n",
    "                    ((img[between] - center) / width + 0.5) * y_range + y_min\n",
    "                )\n",
    "                \n",
    "        return img\n",
    "    \n",
    "    def getExt(self):\n",
    "        return \"dcm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8577abc0",
   "metadata": {
    "papermill": {
     "duration": 0.00514,
     "end_time": "2023-02-25T14:39:19.373167",
     "exception": false,
     "start_time": "2023-02-25T14:39:19.368027",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Loader for pngs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce0a9e7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-25T14:39:19.385518Z",
     "iopub.status.busy": "2023-02-25T14:39:19.385171Z",
     "iopub.status.idle": "2023-02-25T14:39:19.390215Z",
     "shell.execute_reply": "2023-02-25T14:39:19.389178Z"
    },
    "papermill": {
     "duration": 0.013818,
     "end_time": "2023-02-25T14:39:19.392592",
     "exception": false,
     "start_time": "2023-02-25T14:39:19.378774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PreprocessImagePng(PreprocessImage):\n",
    "    def loadXray(self, file_path):\n",
    "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "        return img\n",
    "    \n",
    "    def getExt(self):\n",
    "        return \"png\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e1cd9c",
   "metadata": {
    "papermill": {
     "duration": 0.005573,
     "end_time": "2023-02-25T14:39:19.403681",
     "exception": false,
     "start_time": "2023-02-25T14:39:19.398108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**DataGenerator for Keras model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a666e13e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-25T14:39:19.416148Z",
     "iopub.status.busy": "2023-02-25T14:39:19.415889Z",
     "iopub.status.idle": "2023-02-25T14:39:19.441053Z",
     "shell.execute_reply": "2023-02-25T14:39:19.440163Z"
    },
    "papermill": {
     "duration": 0.033878,
     "end_time": "2023-02-25T14:39:19.443136",
     "exception": false,
     "start_time": "2023-02-25T14:39:19.409258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class XrayDataGenerator (Sequence):\n",
    "    \n",
    "    def __init__(self, loader: PreprocessImage, batch_size=4, new_df=None, saveImages=False, \n",
    "                 saveDF:str=None, shuffle=True,isTest=False, trainSet=0, validation=False, valSplit = 0):\n",
    "        self.loader = loader\n",
    "        self.saveImages=saveImages\n",
    "        self.saveDF = saveDF\n",
    "        if new_df is not None:\n",
    "            if isinstance(new_df, str):\n",
    "                self.new_df = pd.read_csv(new_df)\n",
    "            if isinstance(new_df, pd.DataFrame):\n",
    "                self.new_df = new_df\n",
    "\n",
    "        #colums of new dataSet\n",
    "        #cancer column in train is 1 or 0\n",
    "        #cancer column in test set is [patient_id + _ + laterality]\n",
    "        self.columns_names=[\"patient_id\",\"pred_name\",\"image\",\"age\",\"implant\",'cancer']\n",
    "        #this generator for train or testing\n",
    "        self.isTest = isTest\n",
    "        \n",
    "        #trainSet is part of full train set depended of cancer positive data\n",
    "        #len of newSet = len(cancer_positive_data) + len(cancer_positive_data)*trainSet\n",
    "        self.trainSet = trainSet\n",
    "        self.valSplit = valSplit\n",
    "        self.validation = validation\n",
    "        #if its generator for test set trainSet to 0\n",
    "        if self.isTest:\n",
    "            self.trainSet=0\n",
    "            self.valSplit=0\n",
    "            self.validation = False\n",
    "        \n",
    "        if new_df is None:\n",
    "            self.new_df = pd.DataFrame(columns = self.columns_names)\n",
    "            \n",
    "        self.n = len(self.new_df)\n",
    "            \n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = 43\n",
    "        self.full_df = pd.DataFrame()\n",
    "    \n",
    "    def generateDF(self, csv_path:str):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        cols = ['site_id','patient_id','image_id','laterality','view','age','implant']\n",
    "        if self.isTest!=True:\n",
    "            cols.append('cancer')\n",
    "\n",
    "        df = df[cols]\n",
    "        df['age'] = df['age'].fillna(0)\n",
    "        df['implant'] = df['implant'].fillna(0)\n",
    "\n",
    "        self.new_df = pd.DataFrame(columns = self.columns_names)\n",
    "\n",
    "        self.new_df[['patient_id','age','implant']] = df[['patient_id','age','implant']]\n",
    "        if not self.isTest:\n",
    "            self.new_df['cancer'] = df['cancer']\n",
    "            \n",
    "        self.new_df['pred_name'] = df['patient_id'].astype(str)+'_'+df[\"laterality\"]\n",
    "        self.new_df['image'] = self.loader.getImgPath()+'/'+df['patient_id'].astype(str)+'/'+df['image_id'].astype(str)+'.'+self.loader.getExt()\n",
    "        \n",
    "        if self.saveDF is not None:\n",
    "            self.new_df.to_csv(self.saveDF,index=False)\n",
    "        \n",
    "        self.new_df = self.cropSamples()\n",
    "        \n",
    "        return self.new_df\n",
    "    \n",
    "    def cropSamples(self):\n",
    "          \n",
    "        if self.trainSet!=0:\n",
    "            c_df = self.new_df[self.new_df['cancer']==1]\n",
    "            n_df = self.new_df[self.new_df['cancer']==0].sample(frac=1,random_state=self.random_state).reset_index(drop=True).head( len(c_df)*self.trainSet)\n",
    "            self.new_df = c_df.append(n_df).sample(frac=1,random_state=self.random_state).reset_index(drop=True)\n",
    "     \n",
    "             \n",
    "        indFirst = 0\n",
    "        indLast = len(self.new_df)\n",
    "        \n",
    "        if self.valSplit:\n",
    "            \n",
    "            self.full_df = self.new_df\n",
    "            \n",
    "            if self.validation:\n",
    "                indFirst = int(len(self.new_df)*(1-self.valSplit))\n",
    "            else:\n",
    "                indLast = int(len(self.new_df)*(1-self.valSplit))\n",
    "        \n",
    "        self.new_df = self.new_df[indFirst:indLast]\n",
    "        \n",
    "        self.n = len(self.new_df)\n",
    "        \n",
    "        return self.new_df\n",
    "    \n",
    "    def getValidationSet(self):\n",
    "        if self.valSplit:\n",
    "            genVal = XrayDataGenerator(imgLoader,new_df=self.full_df,trainSet=self.trainSet,valSplit=self.valSplit,validation=True)\n",
    "            genVal.cropSamples()\n",
    "            return genVal\n",
    "        else:\n",
    "            raise Exception('valSplit is zero')\n",
    "    \n",
    "    \n",
    "    def getImage(self, index):\n",
    "        \n",
    "        img = self.loader.readXray(self.new_df.loc[index][\"image\"])  \n",
    "        return img\n",
    "    \n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.new_df = self.new_df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        last_ind = (index + 1) * self.batch_size\n",
    "        if last_ind > self.n:\n",
    "            last_ind = self.n\n",
    "        \n",
    "        batches = self.new_df[index * self.batch_size:last_ind]\n",
    "\n",
    "        X_batch_1 = np.array(\n",
    "                    Parallel(n_jobs=4)(\n",
    "                    delayed(self.getImage)(index)\n",
    "                    for index  in batches.index.values    \n",
    "                    ) )\n",
    "                \n",
    "        #X_batch_1 = (np.asarray([self.getImage(index) for index, x in batches.iterrows()])).astype('float32')\n",
    "        X_batch_2 =  batches[['age','implant']].values.astype('float32')\n",
    "        #X_batch_2 = batches[['age']].values.astype('float32')\n",
    "        #X_batch_2 = np.minimum( (batches[['age']].values /100.0), 1.0).astype('float32')\n",
    "\n",
    "        #return [X_batch_1,X_batch_2],y_batch\n",
    "        if self.isTest:\n",
    "            return [X_batch_1,X_batch_2]\n",
    "            #return X_batch_1\n",
    "        else:\n",
    "            y_batch = batches[\"cancer\"].values.astype('float32')\n",
    "            return [X_batch_1,X_batch_2],y_batch\n",
    "            #return X_batch_1,y_batch\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.n % self.batch_size:\n",
    "            return (self.n // self.batch_size)+1\n",
    "        else:\n",
    "            return (self.n // self.batch_size)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d1e9a9",
   "metadata": {
    "papermill": {
     "duration": 0.005463,
     "end_time": "2023-02-25T14:39:19.454255",
     "exception": false,
     "start_time": "2023-02-25T14:39:19.448792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Test set Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4a7dd32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-25T14:39:19.466754Z",
     "iopub.status.busy": "2023-02-25T14:39:19.466473Z",
     "iopub.status.idle": "2023-02-25T14:39:19.508498Z",
     "shell.execute_reply": "2023-02-25T14:39:19.507575Z"
    },
    "papermill": {
     "duration": 0.050475,
     "end_time": "2023-02-25T14:39:19.510481",
     "exception": false,
     "start_time": "2023-02-25T14:39:19.460006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dicomLoader = PreprocessImageDICOM(test_imgs_path,img_shape,flip=False)\n",
    "testGen = XrayDataGenerator(dicomLoader,batch_size=BATCH_SIZE, isTest=True)\n",
    "test_df = testGen.generateDF(test_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30195829",
   "metadata": {
    "papermill": {
     "duration": 0.005458,
     "end_time": "2023-02-25T14:39:19.521612",
     "exception": false,
     "start_time": "2023-02-25T14:39:19.516154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **KERAS simple model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7e728e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-25T14:39:19.534542Z",
     "iopub.status.busy": "2023-02-25T14:39:19.533769Z",
     "iopub.status.idle": "2023-02-25T14:39:19.945430Z",
     "shell.execute_reply": "2023-02-25T14:39:19.944489Z"
    },
    "papermill": {
     "duration": 0.420662,
     "end_time": "2023-02-25T14:39:19.947924",
     "exception": false,
     "start_time": "2023-02-25T14:39:19.527262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, BatchNormalization, Input\n",
    "from tensorflow.keras.layers import AveragePooling2D, GlobalAveragePooling2D, AveragePooling3D\n",
    "from tensorflow.keras.layers import Add, LayerNormalization, Concatenate, Dropout, Average\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras_cv_attention_models import convnext,resnet_family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47407d37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-25T14:39:19.960383Z",
     "iopub.status.busy": "2023-02-25T14:39:19.960085Z",
     "iopub.status.idle": "2023-02-25T14:39:19.971888Z",
     "shell.execute_reply": "2023-02-25T14:39:19.970681Z"
    },
    "papermill": {
     "duration": 0.02103,
     "end_time": "2023-02-25T14:39:19.974705",
     "exception": false,
     "start_time": "2023-02-25T14:39:19.953675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class pFBeta(tf.keras.metrics.Metric):\n",
    "    def __init__(self, beta=1, name='pF1', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.beta = beta\n",
    "        self.epsilon = 1e-10\n",
    "        self.pos = self.add_weight(name='pos', initializer='zeros')\n",
    "        self.ctp = self.add_weight(name='ctp', initializer='zeros')\n",
    "        self.cfp = self.add_weight(name='cfp', initializer='zeros')\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.clip_by_value(y_pred, 0, 1)\n",
    "        pos = tf.cast(tf.reduce_sum(y_true), tf.float32)\n",
    "        ctp = tf.cast(tf.reduce_sum(y_pred[y_true == 1]), tf.float32)\n",
    "        cfp = tf.cast(tf.reduce_sum(y_pred[y_true == 0]), tf.float32)\n",
    "        self.pos.assign_add(pos)\n",
    "        self.ctp.assign_add(ctp)\n",
    "        self.cfp.assign_add(cfp)\n",
    "        \n",
    "    def result(self):\n",
    "        beta2 = self.beta * self.beta\n",
    "        prec = self.ctp / (self.ctp + self.cfp + self.epsilon)\n",
    "        reca = self.ctp / (self.pos + self.epsilon)\n",
    "        return (1 + beta2) * prec * reca / (beta2 * prec + reca)\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.pos.assign(0.)\n",
    "        self.ctp.assign(0.)\n",
    "        self.cfp.assign(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1eb7f1d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-25T14:39:19.987983Z",
     "iopub.status.busy": "2023-02-25T14:39:19.987674Z",
     "iopub.status.idle": "2023-02-25T14:39:19.997039Z",
     "shell.execute_reply": "2023-02-25T14:39:19.995877Z"
    },
    "papermill": {
     "duration": 0.019096,
     "end_time": "2023-02-25T14:39:19.999788",
     "exception": false,
     "start_time": "2023-02-25T14:39:19.980692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    \n",
    "    input_image = Input(shape=(img_shape[1],img_shape[0],1))\n",
    "    \n",
    "    prepare_image = tf.repeat(input_image, repeats=3, axis=3)\n",
    "       \n",
    "    cnn = convnext.ConvNeXtV2Tiny(input_shape=(img_shape[1], img_shape[0],3), pretrained=None, num_classes=0)(prepare_image)\n",
    "    #cnn = resnet_family.ResNeXt101(input_shape=(img_shape[1], img_shape[0],3), pretrained=None, num_classes=0)(prepare_image)\n",
    "    final_layer = GlobalAveragePooling2D()(cnn)\n",
    "    \n",
    "    age = Input(shape=(2,),name='age_input') #with implants\n",
    "    \n",
    "    final_layer = Concatenate()([final_layer,age])\n",
    "    \n",
    "      #ff\n",
    "    _final_layer = Dense(final_layer.shape[-1]*4,activation='elu')(final_layer)\n",
    "    _final_layer = Dense(final_layer.shape[-1])(_final_layer)\n",
    "    \n",
    "    #relu-add-norm\n",
    "    _final_layer = keras.activations.relu(_final_layer)\n",
    "    final_layer = Add()([_final_layer,final_layer])\n",
    "    final_layer = LayerNormalization(epsilon=1e-6)(final_layer)\n",
    "    \n",
    "        \n",
    "    final_layer = Dense(1,activation='sigmoid')(final_layer)\n",
    "\n",
    "    model = Model([input_image,age], final_layer)\n",
    "    \n",
    "    model.load_weights('/kaggle/input/n-train-one-img-weights-tpu/n_model_768_1344_convnext_ff_ss38_noflip_ep12.h5')\n",
    "    \n",
    "    model.trainable = False\n",
    "\n",
    "    model.compile()\n",
    "\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b14d9a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-25T14:39:20.013762Z",
     "iopub.status.busy": "2023-02-25T14:39:20.013453Z",
     "iopub.status.idle": "2023-02-25T14:39:25.451727Z",
     "shell.execute_reply": "2023-02-25T14:39:25.450586Z"
    },
    "papermill": {
     "duration": 5.448644,
     "end_time": "2023-02-25T14:39:25.454702",
     "exception": false,
     "start_time": "2023-02-25T14:39:20.006058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1344, 768, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.repeat (TFOpLambda)          (None, 1344, 768, No 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "convnext_v2_tiny (Functional)   (None, 42, 24, 768)  27864960    tf.repeat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 768)          0           convnext_v2_tiny[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "age_input (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 770)          0           global_average_pooling2d[0][0]   \n",
      "                                                                 age_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3080)         2374680     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 770)          2372370     dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu (TFOpLambda)         (None, 770)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 770)          0           tf.nn.relu[0][0]                 \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 770)          1540        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            771         layer_normalization[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 32,614,321\n",
      "Trainable params: 0\n",
      "Non-trainable params: 32,614,321\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with STRATEGY.scope():\n",
    "\n",
    "    model = getModel()\n",
    "    \n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36b035b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-25T14:39:25.467654Z",
     "iopub.status.busy": "2023-02-25T14:39:25.467366Z",
     "iopub.status.idle": "2023-02-25T14:39:55.340991Z",
     "shell.execute_reply": "2023-02-25T14:39:55.339766Z"
    },
    "papermill": {
     "duration": 29.883319,
     "end_time": "2023-02-25T14:39:55.344005",
     "exception": false,
     "start_time": "2023-02-25T14:39:25.460686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict = model.predict(testGen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9ec9fe8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-25T14:39:55.359139Z",
     "iopub.status.busy": "2023-02-25T14:39:55.358103Z",
     "iopub.status.idle": "2023-02-25T14:39:55.388227Z",
     "shell.execute_reply": "2023-02-25T14:39:55.387176Z"
    },
    "papermill": {
     "duration": 0.039421,
     "end_time": "2023-02-25T14:39:55.390357",
     "exception": false,
     "start_time": "2023-02-25T14:39:55.350936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_id</th>\n",
       "      <th>cancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10008_L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10008_R</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prediction_id  cancer\n",
       "0       10008_L       0\n",
       "1       10008_R       0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = {'prediction_id': test_df['pred_name'].values ,\n",
    "              \"cancer\":predict[:,0]}\n",
    "submission = pd.DataFrame(submission)\n",
    "submission = pd.DataFrame(submission.groupby('prediction_id')['cancer'].mean()).reset_index()\n",
    "submission['cancer'] = np.int8(submission['cancer'].values > 0.5)\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 121.865529,
   "end_time": "2023-02-25T14:39:58.318308",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-25T14:37:56.452779",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
